
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-conda-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> #prep dataset for ML modeling 
> #
> #
> #library statements
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.4.4     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.0
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(tidytext)
> library(jsonlite)

Attaching package: ‘jsonlite’

The following object is masked from ‘package:purrr’:

    flatten

> library(mikropml)
> 
> #read and unserialize json file
> jsonfile <- "Data/gt_subset_30_data.json"
> json_data <- read_json(jsonfile)  
> json_data <- unserializeJSON(json_data[[1]])
> 
> #set up dataset for 1 ML model; paper, new_seq_data, text_tibble
> json_tibble <- tibble(paper = json_data$`data$paper`,
+                       new_seq_data = json_data$`data$new_seq_data`,
+                       text_tibble = json_data$tibble_data)
> 
> # new column for new_seq_data as binary outcome
> # json_tibble <- mutate(json_tibble, 
> #                      new_seq_data_binary = ifelse(new_seq_data == "Yes", 1, 0))
> 
> # new column for paper as paper_doi
> json_tibble <- rename(json_tibble, paper_doi = paper)
> 
> #need to pull out text tibble so that each word appears by paper
> tidy_tibble <- unnest(json_tibble, cols = text_tibble)
> 
> #implement sparse matrix
> #sparse_matrix <- cast_sparse(tidy_tibble, paper, column = new_seq_data_binary, word, n)
> 
> matrix <- pivot_wider(tidy_tibble, id_cols = c(paper_doi, new_seq_data), names_from = word, 
+                       values_from = n, names_sort = TRUE, values_fill = 0)
> matrix <- select(matrix, !paper_doi)
> 
> ml_model <- run_ml(matrix, method = "glmnet",  outcome_colname = "new_seq_data", seed = 2000)
Using 'new_seq_data' as the outcome column.
Training the model...
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:mikropml’:

    compare_models

The following object is masked from ‘package:purrr’:

    lift

Training complete.
Warning message:
In (function (w)  : `caret::train()` issued the following warning:
 
simpleWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled performance measures.

This warning usually means that the model didn't converge in some cross-validation folds because it is predicting something close to a constant. As a result, certain performance metrics can't be calculated. This suggests that some of the hyperparameters chosen are doing very poorly.
> 
> ml_model$trained_model
glmnet 

  25 samples
8787 predictors
   2 classes: 'No', 'Yes' 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 100 times) 
Summary of sample sizes: 20, 20, 19, 20, 21, 20, ... 
Resampling results across tuning parameters:

  lambda  logLoss    AUC        prAUC      Accuracy   Kappa      F1      
  1e-04   0.8128866  0.6261111  0.4130708  0.6303333  0.2506061  0.718713
  1e-03   0.8128866  0.6261111  0.4130708  0.6303333  0.2506061  0.718713
  1e-02   0.8128866  0.6261111  0.4130708  0.6303333  0.2506061  0.718713
  1e-01   0.8128866  0.6261111  0.4130708  0.6303333  0.2506061  0.718713
  1e+00   0.8128866  0.6261111  0.4130708  0.6303333  0.2506061  0.718713
  1e+01   0.7503853  0.6161111  0.4083903  0.6276000  0.2443313  0.721140
  Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision
  0.8840000    0.369        0.6167001       0.7836538       0.6167001
  0.8840000    0.369        0.6167001       0.7836538       0.6167001
  0.8840000    0.369        0.6167001       0.7836538       0.6167001
  0.8840000    0.369        0.6167001       0.7836538       0.6167001
  0.8840000    0.369        0.6167001       0.7836538       0.6167001
  0.9146667    0.332        0.6110220       0.8209566       0.6110220
  Recall     Detection_Rate  Balanced_Accuracy
  0.8840000  0.4556333       0.6265000        
  0.8840000  0.4556333       0.6265000        
  0.8840000  0.4556333       0.6265000        
  0.8840000  0.4556333       0.6265000        
  0.8840000  0.4556333       0.6265000        
  0.9146667  0.4715333       0.6233333        

Tuning parameter 'alpha' was held constant at a value of 0
AUC was used to select the optimal model using the largest value.
The final values used for the model were alpha = 0 and lambda = 1.
>   
> 
> proc.time()
   user  system elapsed 
263.795  10.368 275.591 
