% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}
\usepackage{xcolor}
\usepackage[margin=1.0in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{setspace}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[left]{lineno}
\linenumbers
\modulolinenumbers
\usepackage{helvet}
\renewcommand*\familydefault{\sfdefault}
\usepackage[T1]{fontenc}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Data Accessibility Paper},
  pdfauthor={Joanna Colovas; Adena Collens; Patrick D. Schloss},
  pdfkeywords={data accessibility, data reproducibility, supervised
machine learning},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Data Accessibility Paper}
\author{Joanna Colovas \and Adena Collens \and Patrick D. Schloss}
\date{Sep 11, 2025}
\begin{document}
\maketitle


\setstretch{1.75}
\begin{itemize}
\item
  Abstract
\item
  Importance

  \begin{itemize}
  \tightlist
  \item
    Incentivize authors to publish/make available their original data
  \item
    Publishing data helps get more use out of research
  \item
    Helps eliminate file drawer effect as it shows negative data
  \end{itemize}
\item
  Keywords

  \begin{itemize}
  \tightlist
  \item
    Data accessibility
  \item
    Data reproducibility
  \end{itemize}
\end{itemize}

\subsection{Introduction}\label{introduction}

Data availability (DA) is the practice of making raw experimental data
and analyses publicly accessible, often via upload in maintained
databases. DA is a newly emerging and yet deeply important component of
the scientific process in the digital age. With the latest and greatest
methodologies available across fields, increasing amounts of data are
being generated each day, especially in the biological sciences.
Availability of these large quantities of study data and metadata (data
about data) is a necessary resource for appropriate use and re-use of
data and protocols as well as the recreation of analyses. We believe
that policies of data ``available on request'' are not sufficient to be
considered available data. One example was published in
\emph{Microbiome}, that a reader in search of data may email the
corresponding author, with varying results ((1)). We believe that this
is simply unacceptable, and set out to determine rates of published raw
data in the biological sciences, specifically microbiology, by examining
the American Society for Microbiology's (ASM) library of published
primary research journals.

\subsubsection{Scientific Data as a Public
Good}\label{scientific-data-as-a-public-good}

The United States Government spent over two hundred million dollars
(USD) in 2024 on research expenditures ((2)). The result of all of these
investments are data, paid for in part by taxpayers. Therefore, data is
a public good, and best used as a benefit to those who provided the
funds for it. Once data has been generated, it can be used not only for
initial analyses, but over and over again in future studies or meta
analyses. Additionally, data can be used to eliminate possible solutions
to a problem by the publishing of ``negative data.'' Thinking of data as
a public good, if negative data is published, it can help researchers
avoid sinking time and financial resources into the investigation of
non-viable hypotheses. This lack of publication of non-fruitful
investigation is more commonly known as the ``file drawer effect.'' Data
as a public good also is subject to the tragedy of the commons. If no
one contributes to the public ``commons'', data that is available for
public use, how can we advance our understanding of our study systems?

\subsubsection{Current DA Policies}\label{current-da-policies}

Current data availability guidelines have been informed by a number of
policies created by funding agencies, peer-review journals, conference
and special task groups, as well as community interest groups. In 2011,
after the Future of Research Communication (FoRC) conference in Germany
to establish FORCE11, a community interest group which seeks to
encourage and promote data availability standards. Also in 2011, the
Genomic Standards Consortium (GSC) published the MIMARKS/MIxS standards
in \emph{Nature Biotechnology} to promote the publication of the
``minimum information about a marker gene sequence'' (MIMARKS) or
``minimum information about x sequence'' (MIxS) ((3)). These standards
are checklists usable by data generators and uploaders towards inclusion
of relevant data with sequence uploads in the International Nucleotide
Sequence Database Collaboration (INSDC).

In 2014 the group published the Joint Declaration of Data Citation
Principles (JDDCP), a document towards the standardization of data
citation and its future availability((\textbf{Data?}) Citation Synthesis
Group 2014). The Findable, Accessible, Interoperable, and Reuseable
(FAIR) data science guiding principles were put forth in 2016 by
Wilkinson et al in \emph{Nature Scientific Data} urges readers to
``improve the infrastructure supporting the reuse of scholarly data''
((4)). Neither the JDDCP nor the FAIR principles are enforcable by any
agency. Finally, the National Institutes of Health (NIH) began enforcing
the ``Policy for Data Management and Sharing'' (NOT-OD-21-013) in
January of 2023, requiring NIH funded studies to submit a data
management and sharing plan (DMS) with their funding applications, and
comply with their DMS plan after generation and publication of the
funded work((\textbf{NIH2023?})). Non-compliance with NOT-OD-21-013 is
identified by funding agencies during annual Research Performance
Progress Reports (RPPRs), and may impact future funding decisions
((\textbf{NIH2023?})).

\subsubsection{ASM Journals}\label{asm-journals}

With the advent of next generation sequencing, microbiology research has
generated large amounts of sequencing data, and it is common to upload
sequence data to a public repository as well as to include data in
research publications. The American Society for Microbiology(ASM) is the
major professional body recognized by microbiologists. They have
eighteen journals, thirteen primary research journals, three review
journals, and two archive journals. In addition, several journals have
been folded into others or renamed over time. The ASM family of journals
requires that authors ``make data fully available, without restriction,
except in rare circumstances'' ((\textbf{ASM?}) open data policy). They
have adapted this policy from journals \emph{Microbial Genomics} and
\emph{PLOS}. In the ASM open data policy they describe the use of a
``Data Availability Statement'' which includes ``data description,
name(s) of the repositories, and digital object identifiers (DOIs) or
accession numbers'' and encourages publishing data on relevant public
repositories ((\textbf{ASM?}) website open data policy). Consequences of
non-compliance to the ASM open data policy include contacting research
article authors to inform of non-compliance, publication of an
``Expression of Concern'' for the author and their compliance issues,
sanctions on publication in ASM journals, as well as contacting the
affiliated research institution and/or funding agencies of the authors
((\textbf{ASMcompliance?})). We endeavor to evaluate how well the
microbiology community is using reproducible data practices as we
believe that this group of researchers will be early adopters of the
technologies available as a result of both the ASM and NIH policies
towards data availability.

\subsubsection{Nucleic Acid Sequencing
Efforts}\label{nucleic-acid-sequencing-efforts}

Beginning in 1996 with the International Strategy Meeting on Human
Genome Sequencing in Bermuda, researchers have prioritized the release
of all human genome sequencing information so that it may ``maximize its
benefit to society'' (@bermuda1996). The meeting participants agreed
that ``primary sequence data should be rapidly released'', with
``sequence assemblies {[}to{]} be released as soon as possible, in some
centres, assemblies of greater than 1 kb would be released automatically
on a daily basis'', and that ``finished annotated sequence should be
submitted immediately to public databases'' (@bermuda1996). The
``Bermuda Principles,'' as they became known, have been embraced by the
large scale Human Genome Project (HGP) since 1998. In 2003, another
meeting, held in Ft. Lauderdale, FL, re-affirmed the 1996 Bermuda
Principles, expanded upon them to apply more broadly towards sequencing
data, and called for further support of these practices (@ftlauderdale).
These foundation agreements set the stage for both the HGP and the Human
Microbiome Project (HMP) to generate and share massive amounts of data
over the course of their studies (@HGP/HMP source needed).

Starting with projects such as the HGP and HMP, nucleic acid sequencing
efforts have been commonly uploaded and released using public databases.
There are three major databases worldwide to support sequencing and
sharing efforts. The National Library of Medicine's (NLM) National
Center for Biotechnology (NCBI) in the United States, the Research
Organization of Information Systems' (ROIS) National Institute of
Genetics (NIG) in Japan, and the European Molecular Biology Lab's (EMBL)
European Bioinformatics Institue (EBI) in Europe. These three databases
are part of the International Nucleotide Sequence Database Collaboration
(INSDC). These large databases make research by comparison possible.
Genetic lineages of microbes are determined by creating phylogenetic
trees which compare a new sequence to existing sequences. Phylogenetic
trees show how closely related a new microbial genetic sequence is
related to others studied before both in terms of evolution and mutation
and in structure and function. An important tool for creating
phylogenies is the NCBI Basic Local Alignment Search Tool (BLAST)
((\textbf{altschul1990?})). The BLAST algorithm allows users to compare
a nucleic acid or protein sequence to the NCBI database of over 1TB of
data to find similar and related sequences. Without the upload of
sequences to the NCBI database, the use and success of BLAST would not
be possible, despite the effort required on part of the researcher to
upload of sequences to one of the INSDC databases.

\subsubsection{Examples of Data
Avalability}\label{examples-of-data-avalability}

A key tenet of the scientific method is the ability to replicate
scientific findings to ensure that they are not due to error. One way
that scientific findings can be replicated is by re-completing the same
analyses by another researcher. This is only possible if the data used
to complete the original analyses is available for use. The availability
of datasets also allows new questions to be answered with existing data
or the combination of multiple datasets, such as the use of the Human
Microbiome Project's (HMP) sequencing data by researchers to create over
650 scientific publications ((\textbf{HMP?})), and the completion of
metadata studies. Availablity of data contributed to the rapid
sequencing of the SARS-CoV-2 virus during the 2020 pandemic and
subsequent expedition of vaccine development ((\textbf{needCOVIDref?})).

With microbiologists commonly uploading nucleic acid sequences to public
databases, the aim of this study was to determine the current state of
data availability in twelve primary research journals from the ASM
family of journals. Primary research articles were classified with using
two machine learning models to answer two questions; ``Does this paper
contain new sequence data?'', and ``Is the data available?'' Once these
questions were answered, we moved to analyses to answer further
questions, ``How does making my data available impact my citation
metrics over time?''

\subsection{Results}\label{results}

\subsubsection{General Description of the
Experiment}\label{general-description-of-the-experiment}

We set out to determine the current state of data availability in twelve
primary research journals from the ASM family of journals. This
objective was completed by first acquiring all papers published in the
journals of interest between 2000 and 2024 using the Crossref database
and command line tools. We then trained random forest machine learning
models to differentiate if each paper contained ``New Sequencing Data''
(NSD) and then if the paper had ``Data Available'' (DA). To avoid
overfitting the model, we trained each model multiple times, performing
validations on a subset of data after each iteration. This allowed us to
have a greater number of papers in the training dataset, as well as to
have great accuracy and precision within our models. Using our trained
models, we were able to classify over 150,000 papers from the whole
dataset to determine if they were NSD or DA. After this, we could
perform statistical modeling to describe the data, and generate summary
statistics. We were especially interested in the ways in which NSD and
DA impact citation metrics.

\subsubsection{ASM Journals}\label{asm-journals-1}

We used twelve of the ASM primary research journals in this study. Of
note, several journals had changes to their publication goals during the
2000-2024 time period. The \emph{Journal of Bacteriology} was the
primary place to publish new genome announcements until 2013 when ASM
announced journal \emph{Genome Announcements} as a more permanent place
for this type of data. \emph{Genome Announcements} was active from 2013
until 2018, when it was re-branded to \emph{Microbiology Resource
Announcements}, which has been active from 2018 until present. These two
journals appear separately in our analyses as a result of the Crossref
database. New genome announcements have a high percentage of NSD papers,
and a high percentage of DA within those papers. As a result, the
\emph{Journal of Bacteriology} has had fewer NSD papers, and fewer
papers with DA since 2013. Another journal of note is \emph{Microbiology
Spectrum} and its re-brand. From 2013 until the fall of 2021,
\emph{Microbiology Spectrum} was a review journal. After this point,
\emph{Microbiology Spectrum} became a primary research journal. Review
journals are less likely to publish articles with NSD, and to have DA.
Several journals, including \emph{Microbiology Spectrum}, do not span
the entire time period for the study. Journals \emph{mBio} (b.2010),
\emph{Microbiology Spectrum} (b. 2013, re-brand 2021), \emph{mSphere}
(b. 2016), \emph{mSystems} (b. 2016), and \emph{Genome Announcements}
(2013-2018). Not all journals are equally likely to contain NSD and have
sequencing DA as a result of their field of interest. Journals
\emph{Antimicrobial Agents and Chemotherapy; Infection and Immunity;}
and the \emph{Journal of Microbiology and Biology Education;} are all
less likely to contain NSD and have DA than the other journals in the
dataset.

\subsubsection{Descriptive Statistics:}\label{descriptive-statistics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.4948}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0825}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1031}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0619}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1031}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0515}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1031}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
container.title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_total
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_fract
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_nsd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
fract\_nsd
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_da
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
fract\_da
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Antimicrobial Agents and Chemotherapy & 82 & 7.846890 & 23 & 28.04878 &
10 & 43.47826 \\
Applied and Environmental Microbiology & 92 & 8.803828 & 38 & 41.30435 &
28 & 73.68421 \\
Genome Announcements & 30 & 2.870813 & 29 & 96.66667 & 29 & 100.00000 \\
Infection and Immunity & 76 & 7.272727 & 16 & 21.05263 & 9 & 56.25000 \\
Journal of Bacteriology & 75 & 7.177034 & 25 & 33.33333 & 15 &
60.00000 \\
Journal of Clinical Microbiology & 77 & 7.368421 & 23 & 29.87013 & 14 &
60.86957 \\
Journal of Microbiology \& Biology Education & 60 & 5.741627 & 0 &
0.00000 & 0 & NaN \\
Journal of Virology & 87 & 8.325359 & 21 & 24.13793 & 6 & 28.57143 \\
mBio & 63 & 6.028708 & 17 & 26.98413 & 11 & 64.70588 \\
Microbiology Resource Announcements & 155 & 14.832536 & 146 & 94.19355 &
145 & 99.31507 \\
Microbiology Spectrum & 111 & 10.622010 & 49 & 44.14414 & 38 &
77.55102 \\
mSphere & 57 & 5.454546 & 25 & 43.85965 & 20 & 80.00000 \\
mSystems & 80 & 7.655502 & 45 & 56.25000 & 45 & 100.00000 \\
\end{longtable}

\begin{verbatim}
# A tibble: 26 x 4
   container.title                                 nsd   da        n
   <chr>                                           <chr> <chr> <int>
 1 Antimicrobial Agents and Chemotherapy           Yes   No     2432
 2 Antimicrobial Agents and Chemotherapy           Yes   Yes     805
 3 Applied and Environmental Microbiology          Yes   No     5998
 4 Applied and Environmental Microbiology          Yes   Yes    2640
 5 Genome Announcements                            Yes   No      324
 6 Genome Announcements                            Yes   Yes    6254
 7 Infection and Immunity                          Yes   No     1574
 8 Infection and Immunity                          Yes   Yes     280
 9 Journal of Bacteriology                         Yes   No     3516
10 Journal of Bacteriology                         Yes   Yes    1351
11 Journal of Clinical Microbiology                Yes   No     3881
12 Journal of Clinical Microbiology                Yes   Yes     493
13 Journal of Microbiology &amp; Biology Education Yes   No        7
14 Journal of Microbiology &amp; Biology Education Yes   Yes       0
15 Journal of Virology                             Yes   No     3647
16 Journal of Virology                             Yes   Yes     936
17 mBio                                            Yes   No      998
18 mBio                                            Yes   Yes    1500
19 Microbiology Resource Announcements             Yes   No       30
20 Microbiology Resource Announcements             Yes   Yes    5708
21 Microbiology Spectrum                           Yes   No      819
22 Microbiology Spectrum                           Yes   Yes    2138
23 mSphere                                         Yes   No      294
24 mSphere                                         Yes   Yes     747
25 mSystems                                        Yes   No      183
26 mSystems                                        Yes   Yes    1253
\end{verbatim}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.5926}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0988}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1358}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0617}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
container.title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_total
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_fract
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
n\_da
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
fract\_da
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Antimicrobial Agents and Chemotherapy & 3237 & 6.7708333 & 805 &
24.86871 \\
Applied and Environmental Microbiology & 8638 & 18.0681058 & 2640 &
30.56263 \\
Genome Announcements & 6578 & 13.7592035 & 6254 & 95.07449 \\
Infection and Immunity & 1854 & 3.8780120 & 280 & 15.10248 \\
Journal of Bacteriology & 4867 & 10.1803046 & 1351 & 27.75837 \\
Journal of Clinical Microbiology & 4374 & 9.1490964 & 493 & 11.27115 \\
Journal of Microbiology \& Biology Education & 7 & 0.0146419 & 0 &
0.00000 \\
Journal of Virology & 4583 & 9.5862617 & 936 & 20.42330 \\
mBio & 2498 & 5.2250669 & 1500 & 60.04804 \\
Microbiology Resource Announcements & 5738 & 12.0021754 & 5708 &
99.47717 \\
Microbiology Spectrum & 2957 & 6.1851573 & 2138 & 72.30301 \\
mSphere & 1041 & 2.1774598 & 747 & 71.75793 \\
mSystems & 1436 & 3.0036814 & 1253 & 87.25627 \\
\end{longtable}

\paragraph{Whole Dataset}\label{whole-dataset}

Using the Crossref database, with validation from WOS, NCBI, and Scopus
databases, we downloaded 155779(XXX- find way to get this not hard coded
in) unique records of papers published in ASM journals between 2000 and
2024. After web scraping there were YYYY papers downloaded with text
available for the models to be applied on, as not all records had text
available. See table YYYY for number of papers downloaded from each
journal. Overall, XXXX\% of papers had NSD, and YYYY\% of papers with
NSD, had DA. See table YYYY for percentages of NSD and DA for each
journal. The journal with the highest rate of NSD was XXXXX at XXXX\%,
and the lowest was XXXX at XXXX\%. The journal with the highest rate of
DA was XXXXX at XXXX\%, and the lowest was XXXX at XXXX\%. This was
expected as \emph{Microbiology Resource Annoucements} publishes mainly
new genomic sequence data and makes the data available. On average,
papers in the dataset had XXXX citations/article. This number varies by
journal, see table YYYY for data by journal. The journal with the
highest rate of citations/article was XXXXX at XXXX\%, and the lowest
was XXXX at XXXX\%. \textbf{SENTENCE ABOUT THIS BEING GOOD AND WHAT WE
WANTED TO SEE IN THIS DATASET}. The journals in the dataset span years
2000-2024. See table YYYYY for the distribution of papers per year in
the dataset.

\paragraph{\texorpdfstring{Training Dataset \textbf{(pretty much the
same as the above paragraph, but with stats for the training
dataset)}}{Training Dataset (pretty much the same as the above paragraph, but with stats for the training dataset)}}\label{training-dataset-pretty-much-the-same-as-the-above-paragraph-but-with-stats-for-the-training-dataset}

We created a subset of the whole dataset to train our machine learning
models. The training dataset initially had N = 500 papers, but was
increased over time due to gaps in the dataset, and after subsequent
validation of the trained models (see below), with a total of N = 1045
Overall, 43.7320574\% of papers had NSD, and 80.9628009\% of papers with
NSD, had DA. See table YYYY for percentages of NSD and DA for each
journal. The journal with the highest rate of NSD was XXXXX at XXXX\%,
and the lowest was XXXX at XXXX\%. The journal with the highest rate of
DA was XXXXX at XXXX\%, and the lowest was XXXX at XXXX\%. This was
expected as \emph{Microbiology Resource Annoucements} publishes mainly
new genomic sequence data and makes the data available. On average,
papers in the dataset had XXXX citations/article. This number varies by
journal, see table YYYY for data by journal. The journal with the
highest rate of citations/article was XXXXX at XXXX\%, and the lowest
was XXXX at XXXX\%. \textbf{SENTENCE ABOUT THIS BEING GOOD AND WHAT WE
WANTED TO SEE IN THIS DATASET}. The journals in the dataset span years
2000-2024. See table YYYYY for the distribution of papers per year in
the dataset.

\subsubsection{Descriptive Statisitcs about the Trained
Models}\label{descriptive-statisitcs-about-the-trained-models}

Two random forest models were trained to predict if published scientific
papers ``contained new sequence data'' (NSD), and if the paper ``had
data available'' (DA), one model for each variable. Other models such as
generalized linear regression and boosted trees were explored, but were
ultimately discarded in favor of the random forest model (data not
shown). Random forest models were chosen to aid in this classification
problem as the creation of many decision trees helps to improve accuracy
and precision. This type of model has one hyperparameter, `mtry' or the
number of predictors to be sampled at each decision. During iterative
model training, a subset of papers were validated after each completed
training and deployment of each model. Papers from each journal, and
extras from certain journals were hand-validated against model
predictions to generate confusion matrices. Confusion matrices for the
final version of each trained model are available in YYYY
table(supplement?). The NSD model used an mtry value of 300 had an Area
Under the Curve(AUC) of 0.9549XXX and an accuracy of 0.8925XXX. The
sensitivity of the NSD model was 0.9130XXX, and the specificity of the
model was 0.8683XXX. The DA model used an mtry value of 400 had an AUC
of 0.9824XXX and an accuracy of 0.9353XXX. The sensitivity of the DA
model was 0.9545XXX, and the specificity of the model was 0.9005XXX
((\textbf{Data/final/best\_model\_stats.csv?}) for internal ref). This
shows that the models fit the data well, and can provide classifications
on new data with an expected error rate of approximately 10\%. We deemed
this as acceptable, accounting for variability in papers and data, and
due to the large size of the dataset to deploy the models on.

\subsubsection{Regression Model using Negative Binomial
Models}\label{regression-model-using-negative-binomial-models}

In this study we sought to investigate the effect of NSD and DA on the
number of citations received by a given paper. We focused on NSD papers
to determine the effect of having DA. This led us to the use of a
negative binomial regression model to best describe our data. All
regression data was NSD yes. We focused on the continuous outcome of
``number of citations'' with predictor variables journal (categorical),
age in months (continuous), and DA status (dichotomous). Due to the
number of citations being fairly bell shaped with a long right tail
(very few papers at advanced age with many citations), the model that
best described our data was the negative binomial regression model. A
negative binomial model is appropriate for data that begins at zero and
has a long `tail' of data. This model also includes a dispersion
parameter to describe the spread of the data. We applied a log
transformation to our age variable (age.in.months) to better describe
the relationship between time and number of citations received. ???HOW
DO I DESCRIBE THE PRODUCED MODEL??? In general, we found that NSD papers
that made DA received more citations over time than those that did not.
See figure YYYY for trends in each major journal. ??HOW else do i
describe the figure??

\subsection{Discussion}\label{discussion}

\begin{itemize}
\tightlist
\item
  Percent of ASM papers that have new sequence data available (nsd Yes,
  da Yes)

  \begin{itemize}
  \tightlist
  \item
    trends by journal
  \item
    trends by year
  \end{itemize}
\item
  Making data available

  \begin{itemize}
  \tightlist
  \item
    provides more citations per paper than not doing so by \emph{XXX}
    number
  \item
    Allows for replication of studies
  \end{itemize}
\item
  Why bother doing this?

  \begin{itemize}
  \tightlist
  \item
    What advantage does it give you as a data generator
  \item
    Is it worth the work?
  \end{itemize}
\item
\end{itemize}

\subsection{Materials and Methods}\label{materials-and-methods}

\subsubsection{Creation of the Training
set}\label{creation-of-the-training-set}

To train our random forest machine learning model, we first created an
appropriate training data set. Using the crossref database, we first
downloaded all papers from the selected ASM family of journals from the
time period beginning January 1st, 2000, and ending on December 31st,
2024. The data was updated as of February 10th, 2025 with all citation
counts frozen at that date. For our initial training set, we chose N =
500 papers from across each journal and time period, adding special
emphasis to include papers that were part of our desired set of interest
(i.e.~contained published data) to ensure that our two models could
adequately characterize each paper as a new sequencing paper and if it
published raw sequencing data or not. After creating our initial
dataset, it was necessary to identify the status of both variables by
hand and determine if each paper contained ``new sequencing data''
(NSD), and if each one had ``data available'' (DA). This was completed
by opening each paper in an internet browser window, and searching for a
``data availability'' or similar statement. See table XXX for specific
cases and how each of these cases were identified for the purpose of
this study.

\subsubsection{Adding Additional Training Set
Papers}\label{adding-additional-training-set-papers}

After initial trainings of our random forest models, a random sampling
of papers was collected for each journal to audit the efficacy of the
models. To audit the efficacy of the models, we hand identified the
status of both variables of interest, NSD and DA. We looked for
weaknesses in the models, and updated methodology to reflect important
areas of interest. For example, in 2023 the ASM journals changed their
formatting to include the data availability statement of a paper in a
sidebar of the webpage. We identified this by noticing that all papers
from journal \emph{Microbiology Resource Announcements} from 2023-2024
were incorrectly characterized by the model as DA = No.~The sidebar of
the webpage was not included in the text the model was considering, and
code had to be updated to include all sidebar data for all papers. These
improvements to the model created a larger and more comprehensive
training set of N = 9XX. These validations allowed us to create
confusion matricies for each model. Confusion matricies for the final
version of each trained model are available in YYYY table(supplement?).

\subsubsection{Descriptive Statistics about the Training
Set}\label{descriptive-statistics-about-the-training-set}

There were XXX papers in the training data set from 12 ASM journals.
These papers came from journals \emph{Applied and Envrionmental
Microbiology; Antimicrobial Agents and Chemotherapy; Infection and
Immunity; Journal of Clinical Biology; Journal of Virology; Journal of
Bacteriology; Journal of Microbiology and Biology Education;
Microbiology Resource Announcments} (formerly known as \emph{Genome
Announcements}); * mSystems; mSphere; mBio; and Microbiology Spectrum.*
See table XXXX for the number of papers from each journal in the
training dataset. The training dataset includes journal articles
published between January 1st, 2000 and December 31st, 2024. See table
XXXXX for the number of papers included from each year from 2000-2024.
XXX\% of training set data was NSD = Yes, and XXX\% of training set data
was DA = Yes.

\subsubsection{Creation of the Training Data from Training
dataset}\label{creation-of-the-training-data-from-training-dataset}

To perform the computational steps required for these experiments, we
used the python tool Snakemake ((\textbf{snakeref?})), and the
University of Michigan's high performance computing cluster
((\textbf{arc?}) ref). Using our selected papers from the training
dataset, we downloaded the entirety of each paper's source HTML using
the command line tool wget. This allowed us to use the source HTML
multiple times for updated analyses without the need to re-query the ASM
webservers numerous times. Next, we performed cleaning of the HTML using
R packages rvest ((\textbf{rvest?}) ref) and xml2 ((\textbf{xml2?}) ref)
to get the desired portions of the paper from the HTML including the
abstract, the body of paper, all tables and figureswith captions, as
well as the side panels for all papers, but especially those containing
the data availability statements in papers published after the 2023
change in webpage format (see above). Then we removed unnecessary text
using R packages tm(text manipulation)((\textbf{tm?}) ref) and textstem
((\textbf{textstem?}) ref), as well as converting all text to lowercase,
and the removal of digits and non-alphabetic characters such as
whitespace. To have the fewest number of unique words, we lemmatized
(sort words by grouping inflected or variant forms of the same word)
words to trace them back to their root words and eliminate any possible
issues with word tense. After this, we created and counted our `tokens',
phrases of up to 1-3 consecutive words from the text of the paper using
R package tokeinziers ((\textbf{tokeinziers?}) ref). Towards the goal of
the fewest meaningful number of words, we used the `Snowball'
((\textbf{snowball?}) ref) dictionary of `stop words' to remove
non-meaningful words such as articles `a', `an', and `the'. We removed
the `space' character with an underscore in multi-word tokens for ease
of procesing, and created a count table for the tokens in each paper.

Once the tokens in each paper were counted, we transformed the data into
a sparse matrix format useable by the R package mikropml
((\textbf{mikropml?}) ref), using R packages caret and dplyr
((\textbf{caret?}) ref, (\textbf{dplyr?}) ref). Tokens were filtered to
those which appear in greater than one paper. This allows comparison
between papers by the model. We removed near zero variants (tokens with
frequency very close to zero) as well as collapsing perfectly correlated
tokens (tokens that always appear together) using R packages caret and
mikropml to reduce model complexity. The data was then simplified to
keep only the following variables; tokens, frequency, journal
information, and hand identified NSD and DA variables. This simiplified
sparse matrix data had the mean and standard deviation calculcated and
saved for the frequency of each token to later apply a z-scoring method
to future data to be predicted by the model.

\subsubsection{Training of the DA and NSD
Models}\label{training-of-the-da-and-nsd-models}

We trained two random forest machine learning models using mikropml's
``run\_ml'' function, one to determine if a paper contained new sequence
data (NSD), and another to determine if the paper had data availabile
(DA). The mikropml ``run\_ml'' function uses methodology described by
Topcuoglu et al ((\textbf{topcuoglu2020?})) to split data for model
training. Random forest models have one hyperparameter to tune, the mtry
value. We began with mtry values of 100, 200, 300, 400, 500, and 600, to
find peak hyperparameter performance given \emph{N tokens}. We trained
the models multiple times in accordance with existing methologies, first
to find the optimal Area Under the Receiver-Operator Curve (AUROC) value
for each model with N=100 seeds. Then to find the best mtry performance
for each model, with N=1 seed. Finally, with N=1 seed to train each
final model for use on experimental data.

\subsubsection{Preparation of the Experimental
Dataset}\label{preparation-of-the-experimental-dataset}

To fully answer our research questions, we created a larger database
with N = 155779 papers curated from reference datasets Crossref, NCBI,
Scopus, and the Web of Science ((\textbf{crossref?}), (\textbf{ncbi?}),
(\textbf{scopus?}), (\textbf{wos?})). These papers span all twelve ASM
journals of interest from the start of 2000 to the end of 2024. Once
database was curated, we applied the same steps to ready papers for
application of machine learning models as the model training datasets.
See above for descriptions of webscraping html, cleaning html, removing
unnecessary text, and creation of token count table for application in
each of the machine learning models to determine the NSD and DA statuses
for each paper. Once the frequency count tables were prepared for each
paper, a z-score was applied using the saved data from each model
appropriately, using the formula XXX((observed\_token\_frequency -
model\_token\_frequency\_mean)/(model\_token\_frequency\_sd)). This
z-scoring formula was applied to standardize the frequency of each
token. Only tokens included in the machine learning models were retained
in experimental datasets. Finally, each model was deployed on each paper
to determine its NSD and DA status.

\begin{itemize}
\tightlist
\item
  Statistical methodology

  \begin{itemize}
  \tightlist
  \item
    negative binomial modeling using r package MASS

    \begin{itemize}
    \tightlist
    \item
      fixed modeling
    \item
      log transformation of age.in.months
    \item
      95\% CI
    \end{itemize}
  \end{itemize}
\item
  Supplemental Material file list (where applicable)
\item
  Acknowledgments
\item
  References
\item
  Figures/Tables/stats to make/get

  \begin{itemize}
  \tightlist
  \item
    Table showing \# of papers from each journal in training dataset
  \item
    Table showing \# of papers from each year in training dataset
  \item
    \% of papers nsd yes total (training)
  \item
    \% of papers da yes total (training)
  \item
    table of conditions to add to the methods of classification?
  \end{itemize}
\end{itemize}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\bibitem[\citeproctext]{ref-langille_available_2018}
\CSLLeftMargin{1. }%
\CSLRightInline{\textbf{Langille MGI}, \textbf{Ravel J}, \textbf{Fricke
WF}. 2018. {``{Available} upon request''}: Not good enough for
microbiome data! Microbiome \textbf{6}:8.
doi:\href{https://doi.org/10.1186/s40168-017-0394-z}{10.1186/s40168-017-0394-z}.}

\bibitem[\citeproctext]{ref-congress2024}
\CSLLeftMargin{2. }%
\CSLRightInline{\href{https://www.congress.gov/crs-product/R47564}{Federal
{Research} and {Development} ({R}\&{D}) {Funding}: {FY2024}}.
legislation.}

\bibitem[\citeproctext]{ref-yilmaz_minimum_2011}
\CSLLeftMargin{3. }%
\CSLRightInline{\textbf{Yilmaz P}, \textbf{Field D}, \textbf{Knight R},
\textbf{Cole JR}, \textbf{Amaral-Zettler L}, \textbf{Gilbert JA},
\textbf{Karsch-Mizrachi I}, \textbf{Johnston A}, \textbf{Cochrane G},
\textbf{Vaughan R}, \textbf{Hunter C}, \textbf{Park J}, \textbf{Morrison
N}, \textbf{Rocca-Serra P}, \textbf{Sterk P}, \textbf{Arumugam M},
\textbf{Bailey M}, \textbf{Baumgartner L}, \textbf{Birren BW},
\textbf{Blaser MJ}, \textbf{Bonazzi V}, \textbf{Booth T}, \textbf{Bork
P}, \textbf{Bushman FD}, \textbf{Buttigieg PL}, \textbf{Chain PSG},
\textbf{Charlson E}, \textbf{Costello EK}, \textbf{Huot-Creasy H},
\textbf{Dawyndt P}, \textbf{DeSantis T}, \textbf{Fierer N},
\textbf{Fuhrman JA}, \textbf{Gallery RE}, \textbf{Gevers D},
\textbf{Gibbs RA}, \textbf{Gil IS}, \textbf{Gonzalez A}, \textbf{Gordon
JI}, \textbf{Guralnick R}, \textbf{Hankeln W}, \textbf{Highlander S},
\textbf{Hugenholtz P}, \textbf{Jansson J}, \textbf{Kau AL},
\textbf{Kelley ST}, \textbf{Kennedy J}, \textbf{Knights D},
\textbf{Koren O}, \textbf{Kuczynski J}, \textbf{Kyrpides N},
\textbf{Larsen R}, \textbf{Lauber CL}, \textbf{Legg T}, \textbf{Ley RE},
\textbf{Lozupone CA}, \textbf{Ludwig W}, \textbf{Lyons D},
\textbf{Maguire E}, \textbf{Methé BA}, \textbf{Meyer F}, \textbf{Muegge
B}, \textbf{Nakielny S}, \textbf{Nelson KE}, \textbf{Nemergut D},
\textbf{Neufeld JD}, \textbf{Newbold LK}, \textbf{Oliver AE},
\textbf{Pace NR}, \textbf{Palanisamy G}, \textbf{Peplies J},
\textbf{Petrosino J}, \textbf{Proctor L}, \textbf{Pruesse E},
\textbf{Quast C}, \textbf{Raes J}, \textbf{Ratnasingham S},
\textbf{Ravel J}, \textbf{Relman DA}, \textbf{Assunta-Sansone S},
\textbf{Schloss PD}, \textbf{Schriml L}, \textbf{Sinha R}, \textbf{Smith
MI}, \textbf{Sodergren E}, \textbf{Spor A}, \textbf{Stombaugh J},
\textbf{Tiedje JM}, \textbf{Ward DV}, \textbf{Weinstock GM},
\textbf{Wendel D}, \textbf{White O}, \textbf{Whiteley A}, \textbf{Wilke
A}, \textbf{Wortman JR}, \textbf{Yatsunenko T}, \textbf{Glöckner FO}.
2011. Minimum information about a marker gene sequence ({MIMARKS}) and
minimum information about any (x) sequence ({MIxS}) specifications.
Nature Biotechnology \textbf{29}:415--420.
doi:\href{https://doi.org/10.1038/nbt.1823}{10.1038/nbt.1823}.}

\bibitem[\citeproctext]{ref-wilkinson_fair_2016}
\CSLLeftMargin{4. }%
\CSLRightInline{\textbf{Wilkinson MD}, \textbf{Dumontier M},
\textbf{Aalbersberg IjJ}, \textbf{Appleton G}, \textbf{Axton M},
\textbf{Baak A}, \textbf{Blomberg N}, \textbf{Boiten J-W}, \textbf{Silva
Santos LB da}, \textbf{Bourne PE}, \textbf{Bouwman J}, \textbf{Brookes
AJ}, \textbf{Clark T}, \textbf{Crosas M}, \textbf{Dillo I},
\textbf{Dumon O}, \textbf{Edmunds S}, \textbf{Evelo CT}, \textbf{Finkers
R}, \textbf{Gonzalez-Beltran A}, \textbf{Gray AJG}, \textbf{Groth P},
\textbf{Goble C}, \textbf{Grethe JS}, \textbf{Heringa J}, \textbf{Hoen
PAC 't}, \textbf{Hooft R}, \textbf{Kuhn T}, \textbf{Kok R}, \textbf{Kok
J}, \textbf{Lusher SJ}, \textbf{Martone ME}, \textbf{Mons A},
\textbf{Packer AL}, \textbf{Persson B}, \textbf{Rocca-Serra P},
\textbf{Roos M}, \textbf{Schaik R van}, \textbf{Sansone S-A},
\textbf{Schultes E}, \textbf{Sengstag T}, \textbf{Slater T},
\textbf{Strawn G}, \textbf{Swertz MA}, \textbf{Thompson M}, \textbf{Lei
J van der}, \textbf{Mulligen E van}, \textbf{Velterop J},
\textbf{Waagmeester A}, \textbf{Wittenburg P}, \textbf{Wolstencroft K},
\textbf{Zhao J}, \textbf{Mons B}. 2016. The {FAIR} {Guiding}
{Principles} for scientific data management and stewardship. Scientific
Data \textbf{3}:160018.
doi:\href{https://doi.org/10.1038/sdata.2016.18}{10.1038/sdata.2016.18}.}

\end{CSLReferences}




\end{document}
