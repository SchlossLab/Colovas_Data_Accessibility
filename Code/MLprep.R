#prep dataset for ML modeling 
#
# 20240429 MLprep.R of groundtruth, groundtruth_subset30
# using mikropml and model glmnet to train model to predict
# variable new_seq_data
#
#library statements
library(tidyverse)
library(tidytext)
library(jsonlite)
library(mikropml)

# 20240528 - using gtss30/generic files generated by snakemake------------------
# practice using mikropml and getting formatting right


# load files

# for snakemake implementation
# {input.rscript} {input.metadata} {input.ml_vars} {input.tokens} {output}
input <- commandArgs(trailingOnly = TRUE)
metadata <- input[1]
ml_var_snake <- input[2]
ml_var <- c("paper", ml_var_snake, "container.title")
clean_csv <- input[3]
output_file <- input[4]
clean_text <- read.csv(clean_csv)
metadata <- read.csv(metadata)

# #other implementation
# clean_text <- read.csv("Data/gt_subset_30_tokens.csv.gz")
# metadata <- read.csv("Data/gt_subset_30.csv")
# ml_var_snake <- "new_seq_data"
# ml_var <- c("paper", ml_var_snake, "container.title")


# set up the format of the clean_text dataframe 

# each token is a column 
clean_tibble <- pivot_wider(clean_text, id_cols = c(paper_doi),
                           names_from = paper_tokens, values_from = frequency,
                           names_sort = TRUE, values_fill = 0) 

# need metadata for the papers
need_meta <- select(metadata, all_of(ml_var))

# join clean_tibble and need_meta 
full_ml <- left_join(need_meta, clean_tibble, by = join_by(paper == paper_doi))

# remove paper doi
full_ml <- select(full_ml, !paper)

# use mikropml::preprocess_data on dataset
full_ml_pre <- preprocess_data(full_ml, outcome_colname = ml_var_snake)
# colnames(full_ml_pre$dat_transformed)

# run model using mikropml::run_ml
ml_model <- run_ml(full_ml_pre$dat_transformed,
                          method = "glmnet",  outcome_colname = ml_var_snake,
                          find_feature_importance = TRUE, 
                          seed = 2000)
ml_model

