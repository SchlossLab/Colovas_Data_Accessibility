Using profile config_files/ for setting default command line arguments.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 4999
Job stats:
job          count
---------  -------
cleanHTML        1
ml_prep          1
targets          1
tokenize         1
total            4

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:00:26 2024]
rule cleanHTML:
    input: Data/gt_subset_30.html.csv.gz, Code/cleanHTML.R
    output: Data/gt_subset_30.cleanhtml.csv.gz
    jobid: 3
    reason: Missing output files: Data/gt_subset_30.cleanhtml.csv.gz; Updated input files: Code/cleanHTML.R, Data/gt_subset_30.html.csv.gz
    wildcards: datasets=gt_subset_30
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/cleanHTML.R Data/gt_subset_30.html.csv.gz Data/gt_subset_30.cleanhtml.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "cleanHTML", "local": false, "input": ["Data/gt_subset_30.html.csv.gz", "Code/cleanHTML.R"], "output": ["Data/gt_subset_30.cleanhtml.csv.gz"], "wildcards": {"datasets": "gt_subset_30"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 3, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'cleanHTML:datasets=gt_subset_30' --allowed-rules 'cleanHTML' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_' 'Data/gt_subset_30.html.csv.gz' 'Code/cleanHTML.R' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/3.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/3.jobfailed'; exit 1)

Submitted job 3 with external jobid 'Submitted batch job 9704164'.
[Tue Jun 18 11:04:07 2024]
Finished job 3.
1 of 4 steps (25%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:04:07 2024]
rule tokenize:
    input: Data/gt_subset_30.cleanhtml.csv.gz, Code/tokenize.R
    output: Data/gt_subset_30.tokens.csv.gz
    jobid: 2
    reason: Input files updated by another job: Data/gt_subset_30.cleanhtml.csv.gz
    wildcards: datasets=gt_subset_30
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/tokenize.R Data/gt_subset_30.cleanhtml.csv.gz Data/gt_subset_30.tokens.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "tokenize", "local": false, "input": ["Data/gt_subset_30.cleanhtml.csv.gz", "Code/tokenize.R"], "output": ["Data/gt_subset_30.tokens.csv.gz"], "wildcards": {"datasets": "gt_subset_30"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 2, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'tokenize:datasets=gt_subset_30' --allowed-rules 'tokenize' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_' 'Data/gt_subset_30.cleanhtml.csv.gz' 'Code/tokenize.R' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/2.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/2.jobfailed'; exit 1)

Submitted job 2 with external jobid 'Submitted batch job 9704564'.
[Tue Jun 18 11:04:47 2024]
Finished job 2.
2 of 4 steps (50%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:04:47 2024]
rule ml_prep:
    input: Data/gt_subset_30.tokens.csv.gz, Code/MLprep.R, Data/gt_subset_30.csv
    output: Data/gt_subset_30.new_seq_data.preprocessed.RDS
    jobid: 1
    reason: Input files updated by another job: Data/gt_subset_30.tokens.csv.gz
    wildcards: datasets=gt_subset_30, ml_variables=new_seq_data
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/MLprep.R Data/gt_subset_30.csv Data/gt_subset_30.tokens.csv.gz new_seq_data 1 Data/gt_subset_30.new_seq_data.preprocessed.RDS
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "ml_prep", "local": false, "input": ["Data/gt_subset_30.tokens.csv.gz", "Code/MLprep.R", "Data/gt_subset_30.csv"], "output": ["Data/gt_subset_30.new_seq_data.preprocessed.RDS"], "wildcards": {"datasets": "gt_subset_30", "ml_variables": "new_seq_data"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 1, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'ml_prep:datasets=gt_subset_30,ml_variables=new_seq_data' --allowed-rules 'ml_prep' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_' 'Data/gt_subset_30.tokens.csv.gz' 'Code/MLprep.R' 'Data/gt_subset_30.csv' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/1.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.j_d3odx_/1.jobfailed'; exit 1)

Submitted job 1 with external jobid 'Submitted batch job 9704711'.
[Tue Jun 18 11:06:27 2024]
Finished job 1.
3 of 4 steps (75%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:06:27 2024]
localrule targets:
    input: Data/gt_subset_30.new_seq_data.preprocessed.RDS
    jobid: 0
    reason: Input files updated by another job: Data/gt_subset_30.new_seq_data.preprocessed.RDS
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=/tmp, cpus=1, time=24:00:00, job_name=data

[Tue Jun 18 11:06:27 2024]
Finished job 0.
4 of 4 steps (100%) done
Complete log: .snakemake/log/2024-06-18T110022.325012.snakemake.log
unlocking
removing lock
removing lock
removed all locks
