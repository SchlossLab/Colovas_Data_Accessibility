Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 4999
Job stats:
job        count
-------  -------
ml_prep        2
targets        1
total          3

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (2)
Select jobs to execute...
Selected jobs (2)
Resources after job selection: {'_cores': 9223372036854775805, '_nodes': 4997}

[Wed Jun 19 16:48:54 2024]
rule ml_prep:
    input: Data/groundtruth.tokens.csv.gz, Code/MLprep.R, Data/groundtruth.csv
    output: Data/groundtruth.new_seq_data.preprocessed.RDS
    jobid: 1
    reason: Missing output files: Data/groundtruth.new_seq_data.preprocessed.RDS
    wildcards: datasets=groundtruth, ml_variables=new_seq_data
    resources: mem_mb=200000, mem_mib=190735, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/MLprep.R Data/groundtruth.csv Data/groundtruth.tokens.csv.gz new_seq_data 1 Data/groundtruth.new_seq_data.preprocessed.RDS
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "ml_prep", "local": false, "input": ["Data/groundtruth.tokens.csv.gz", "Code/MLprep.R", "Data/groundtruth.csv"], "output": ["Data/groundtruth.new_seq_data.preprocessed.RDS"], "wildcards": {"datasets": "groundtruth", "ml_variables": "new_seq_data"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 200000, "mem_mib": 190735, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 1, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'ml_prep:datasets=groundtruth,ml_variables=new_seq_data' --allowed-rules 'ml_prep' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=200000' 'mem_mib=190735' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6' 'Data/groundtruth.tokens.csv.gz' 'Code/MLprep.R' 'Data/groundtruth.csv' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'software-env' 'params' 'input' 'code' 'mtime' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6/1.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6/1.jobfailed'; exit 1)

Error submitting jobscript (exit code 1):


[Wed Jun 19 16:49:05 2024]
rule ml_prep:
    input: Data/gt_subset_30.tokens.csv.gz, Code/MLprep.R, Data/gt_subset_30.csv
    output: Data/gt_subset_30.new_seq_data.preprocessed.RDS
    jobid: 5
    reason: Updated input files: Code/MLprep.R
    wildcards: datasets=gt_subset_30, ml_variables=new_seq_data
    resources: mem_mb=200000, mem_mib=190735, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/MLprep.R Data/gt_subset_30.csv Data/gt_subset_30.tokens.csv.gz new_seq_data 1 Data/gt_subset_30.new_seq_data.preprocessed.RDS
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "ml_prep", "local": false, "input": ["Data/gt_subset_30.tokens.csv.gz", "Code/MLprep.R", "Data/gt_subset_30.csv"], "output": ["Data/gt_subset_30.new_seq_data.preprocessed.RDS"], "wildcards": {"datasets": "gt_subset_30", "ml_variables": "new_seq_data"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 200000, "mem_mib": 190735, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 5, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'ml_prep:datasets=gt_subset_30,ml_variables=new_seq_data' --allowed-rules 'ml_prep' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=200000' 'mem_mib=190735' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6' 'Data/gt_subset_30.tokens.csv.gz' 'Code/MLprep.R' 'Data/gt_subset_30.csv' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'software-env' 'params' 'input' 'code' 'mtime' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6/5.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.e4nxbi_6/5.jobfailed'; exit 1)

Error submitting jobscript (exit code 1):

Cleanup job metadata.
Cleanup failed jobs output files.
Cleanup job metadata.
Cleanup failed jobs output files.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-19T164850.905845.snakemake.log
unlocking
removing lock
removing lock
removed all locks
