Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 4999
Job stats:
job              count
-------------  -------
link_rot             1
lr_by_journal        1
lr_by_status         1
targets              1
total                4

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Thu Jun 20 16:56:38 2024]
rule link_rot:
    input: Data/groundtruth.html.csv.gz, Code/LinkRot.R, Data/groundtruth.csv
    output: Data/linkrot/groundtruth.alllinks.csv.gz, Data/linkrot/groundtruth.linksmetadata.csv.gz
    jobid: 2
    reason: Missing output files: Data/linkrot/groundtruth.alllinks.csv.gz, Data/linkrot/groundtruth.linksmetadata.csv.gz
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/LinkRot.R  Data/groundtruth.html.csv.gz Data/groundtruth.csv Data/linkrot/groundtruth.alllinks.csv.gz Data/linkrot/groundtruth.linksmetadata.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "link_rot", "local": false, "input": ["Data/groundtruth.html.csv.gz", "Code/LinkRot.R", "Data/groundtruth.csv"], "output": ["Data/linkrot/groundtruth.alllinks.csv.gz", "Data/linkrot/groundtruth.linksmetadata.csv.gz"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 2, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'link_rot:datasets=groundtruth' --allowed-rules 'link_rot' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0' 'Data/groundtruth.html.csv.gz' 'Code/LinkRot.R' 'Data/groundtruth.csv' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'input' 'code' 'params' 'mtime' 'software-env' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/2.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/2.jobfailed'; exit 1)

Submitted job 2 with external jobid 'Submitted batch job 9831450'.
[Thu Jun 20 17:06:19 2024]
Finished job 2.
1 of 4 steps (25%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (2)
Select jobs to execute...
Selected jobs (2)
Resources after job selection: {'_cores': 9223372036854775805, '_nodes': 4997}

[Thu Jun 20 17:06:19 2024]
rule lr_by_status:
    input: Code/linkrot/links_bystatus.R, Data/linkrot/groundtruth.alllinks.csv.gz
    output: Figures/linkrot/groundtruth/alllinks_bystatus.png, Figures/linkrot/groundtruth/uniquelinks_bystatus.png
    jobid: 1
    reason: Missing output files: Figures/linkrot/groundtruth/alllinks_bystatus.png; Input files updated by another job: Data/linkrot/groundtruth.alllinks.csv.gz
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/linkrot/links_bystatus.R Data/linkrot/groundtruth.alllinks.csv.gz Figures/linkrot/groundtruth/alllinks_bystatus.png Figures/linkrot/groundtruth/uniquelinks_bystatus.png
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "lr_by_status", "local": false, "input": ["Code/linkrot/links_bystatus.R", "Data/linkrot/groundtruth.alllinks.csv.gz"], "output": ["Figures/linkrot/groundtruth/alllinks_bystatus.png", "Figures/linkrot/groundtruth/uniquelinks_bystatus.png"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 1, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'lr_by_status:datasets=groundtruth' --allowed-rules 'lr_by_status' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0' 'Code/linkrot/links_bystatus.R' 'Data/linkrot/groundtruth.alllinks.csv.gz' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'input' 'code' 'params' 'mtime' 'software-env' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/1.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/1.jobfailed'; exit 1)

Submitted job 1 with external jobid 'Submitted batch job 9831670'.

[Thu Jun 20 17:06:19 2024]
rule lr_by_journal:
    input: Code/linkrot/links_byjournal.R, Data/linkrot/groundtruth.linksmetadata.csv.gz
    output: Figures/linkrot/groundtruth/links_byjournal.png
    jobid: 4
    reason: Input files updated by another job: Data/linkrot/groundtruth.linksmetadata.csv.gz
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/linkrot/links_byjournal.R Data/linkrot/groundtruth.linksmetadata.csv.gz Figures/linkrot/groundtruth/links_byjournal.png
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "lr_by_journal", "local": false, "input": ["Code/linkrot/links_byjournal.R", "Data/linkrot/groundtruth.linksmetadata.csv.gz"], "output": ["Figures/linkrot/groundtruth/links_byjournal.png"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 4, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'lr_by_journal:datasets=groundtruth' --allowed-rules 'lr_by_journal' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0' 'Code/linkrot/links_byjournal.R' 'Data/linkrot/groundtruth.linksmetadata.csv.gz' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'input' 'code' 'params' 'mtime' 'software-env' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/4.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/4.jobfailed'; exit 1)

Submitted job 4 with external jobid 'Submitted batch job 9831671'.
[Thu Jun 20 17:07:59 2024]
Error in rule lr_by_status:
    jobid: 1
    input: Code/linkrot/links_bystatus.R, Data/linkrot/groundtruth.alllinks.csv.gz
    output: Figures/linkrot/groundtruth/alllinks_bystatus.png, Figures/linkrot/groundtruth/uniquelinks_bystatus.png
    shell:
        
        Code/linkrot/links_bystatus.R Data/linkrot/groundtruth.alllinks.csv.gz Figures/linkrot/groundtruth/alllinks_bystatus.png Figures/linkrot/groundtruth/uniquelinks_bystatus.png
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 9831670

Error executing rule lr_by_status on cluster (jobid: 1, external: Submitted batch job 9831670, jobscript: /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/snakejob.lr_by_status.1.sh). For error details see the cluster log and the log files of the involved rule(s).
Cleanup job metadata.
Cleanup failed jobs output files.
[Thu Jun 20 17:07:59 2024]
Error in rule lr_by_journal:
    jobid: 4
    input: Code/linkrot/links_byjournal.R, Data/linkrot/groundtruth.linksmetadata.csv.gz
    output: Figures/linkrot/groundtruth/links_byjournal.png
    shell:
        
        Code/linkrot/links_byjournal.R Data/linkrot/groundtruth.linksmetadata.csv.gz Figures/linkrot/groundtruth/links_byjournal.png
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 9831671

Error executing rule lr_by_journal on cluster (jobid: 4, external: Submitted batch job 9831671, jobscript: /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.opzm9gq0/snakejob.lr_by_journal.4.sh). For error details see the cluster log and the log files of the involved rule(s).
Cleanup job metadata.
Cleanup failed jobs output files.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-20T165635.166525.snakemake.log
unlocking
removing lock
removing lock
removed all locks
