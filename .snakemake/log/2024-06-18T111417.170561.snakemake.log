Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 4999
Job stats:
job          count
---------  -------
cleanHTML        1
ml_prep          1
targets          1
tokenize         1
webscrape        1
total            5

Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:14:20 2024]
rule webscrape:
    input: Data/groundtruth.csv, Code/Webscrape.R
    output: Data/groundtruth.html.csv.gz
    jobid: 4
    reason: Missing output files: Data/groundtruth.html.csv.gz
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/Webscrape.R Data/groundtruth.csv Data/groundtruth.html.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "webscrape", "local": false, "input": ["Data/groundtruth.csv", "Code/Webscrape.R"], "output": ["Data/groundtruth.html.csv.gz"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 4, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'webscrape:datasets=groundtruth' --allowed-rules 'webscrape' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0' 'Data/groundtruth.csv' 'Code/Webscrape.R' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/4.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/4.jobfailed'; exit 1)

Submitted job 4 with external jobid 'Submitted batch job 9705686'.
[Tue Jun 18 11:36:01 2024]
Finished job 4.
1 of 5 steps (20%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:36:01 2024]
rule cleanHTML:
    input: Data/groundtruth.html.csv.gz, Code/cleanHTML.R
    output: Data/groundtruth.cleanhtml.csv.gz
    jobid: 3
    reason: Missing output files: Data/groundtruth.cleanhtml.csv.gz; Input files updated by another job: Data/groundtruth.html.csv.gz
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/cleanHTML.R Data/groundtruth.html.csv.gz Data/groundtruth.cleanhtml.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "cleanHTML", "local": false, "input": ["Data/groundtruth.html.csv.gz", "Code/cleanHTML.R"], "output": ["Data/groundtruth.cleanhtml.csv.gz"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 3, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'cleanHTML:datasets=groundtruth' --allowed-rules 'cleanHTML' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0' 'Data/groundtruth.html.csv.gz' 'Code/cleanHTML.R' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/3.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/3.jobfailed'; exit 1)

Submitted job 3 with external jobid 'Submitted batch job 9706084'.
[Tue Jun 18 11:36:41 2024]
Finished job 3.
2 of 5 steps (40%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:36:41 2024]
rule tokenize:
    input: Data/groundtruth.cleanhtml.csv.gz, Code/tokenize.R
    output: Data/groundtruth.tokens.csv.gz
    jobid: 2
    reason: Missing output files: Data/groundtruth.tokens.csv.gz; Input files updated by another job: Data/groundtruth.cleanhtml.csv.gz; Set of input files has changed since last execution; Code has changed since last execution
    wildcards: datasets=groundtruth
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/tokenize.R Data/groundtruth.cleanhtml.csv.gz Data/groundtruth.tokens.csv.gz
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "tokenize", "local": false, "input": ["Data/groundtruth.cleanhtml.csv.gz", "Code/tokenize.R"], "output": ["Data/groundtruth.tokens.csv.gz"], "wildcards": {"datasets": "groundtruth"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 2, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'tokenize:datasets=groundtruth' --allowed-rules 'tokenize' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0' 'Data/groundtruth.cleanhtml.csv.gz' 'Code/tokenize.R' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/2.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/2.jobfailed'; exit 1)

Submitted job 2 with external jobid 'Submitted batch job 9706128'.
[Tue Jun 18 11:38:22 2024]
Finished job 2.
3 of 5 steps (60%) done
Resources before job selection: {'_cores': 9223372036854775807, '_nodes': 4999}
Ready jobs (1)
Select jobs to execute...
Selected jobs (1)
Resources after job selection: {'_cores': 9223372036854775806, '_nodes': 4998}

[Tue Jun 18 11:38:22 2024]
rule ml_prep:
    input: Data/groundtruth.tokens.csv.gz, Code/MLprep.R, Data/groundtruth.csv
    output: Data/groundtruth.new_seq_data.preprocessed.RDS
    jobid: 1
    reason: Missing output files: Data/groundtruth.new_seq_data.preprocessed.RDS; Input files updated by another job: Data/groundtruth.tokens.csv.gz
    wildcards: datasets=groundtruth, ml_variables=new_seq_data
    resources: mem_mb=10000, mem_mib=9537, disk_mb=1000, disk_mib=954, tmpdir=<TBD>, cpus=1, time=24:00:00, job_name=data


        Code/MLprep.R Data/groundtruth.csv Data/groundtruth.tokens.csv.gz new_seq_data 1 Data/groundtruth.new_seq_data.preprocessed.RDS
        
Jobscript:
#!/bin/sh
# properties = {"type": "single", "rule": "ml_prep", "local": false, "input": ["Data/groundtruth.tokens.csv.gz", "Code/MLprep.R", "Data/groundtruth.csv"], "output": ["Data/groundtruth.new_seq_data.preprocessed.RDS"], "wildcards": {"datasets": "groundtruth", "ml_variables": "new_seq_data"}, "params": {}, "log": [], "threads": 1, "resources": {"mem_mb": 10000, "mem_mib": 9537, "disk_mb": 1000, "disk_mib": 954, "tmpdir": "<TBD>", "cpus": 1, "time": "24:00:00", "job_name": "data"}, "jobid": 1, "cluster": {}}
cd /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility && /home/jocolova/miniforge3/envs/data_acc/bin/python3.12 -m snakemake --snakefile '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile' --target-jobs 'ml_prep:datasets=groundtruth,ml_variables=new_seq_data' --allowed-rules 'ml_prep' --cores 'all' --attempt 1 --force-use-threads  --resources 'mem_mb=10000' 'mem_mib=9537' 'disk_mb=1000' 'disk_mib=954' 'cpus=1' --wait-for-files '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0' 'Data/groundtruth.tokens.csv.gz' 'Code/MLprep.R' 'Data/groundtruth.csv' --force --keep-target-files --keep-remote --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers 'mtime' 'software-env' 'code' 'params' 'input' --skip-script-cleanup  --use-conda  --conda-frontend 'mamba' --conda-base-path '/home/jocolova/miniforge3' --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --printshellcmds  --latency-wait 120 --scheduler 'greedy' --scheduler-solver-path '/home/jocolova/miniforge3/envs/data_acc/bin' --default-resources 'mem_mb=10000' 'disk_mb=max(2*input.size_mb, 1000)' 'tmpdir=system_tmpdir' 'cpus=1' 'time="24:00:00"' 'job_name="data"' --mode 2 && touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/1.jobfinished' || (touch '/nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/1.jobfailed'; exit 1)

Submitted job 1 with external jobid 'Submitted batch job 9706206'.
[Tue Jun 18 11:41:02 2024]
Error in rule ml_prep:
    jobid: 1
    input: Data/groundtruth.tokens.csv.gz, Code/MLprep.R, Data/groundtruth.csv
    output: Data/groundtruth.new_seq_data.preprocessed.RDS
    shell:
        
        Code/MLprep.R Data/groundtruth.csv Data/groundtruth.tokens.csv.gz new_seq_data 1 Data/groundtruth.new_seq_data.preprocessed.RDS
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 9706206

Error executing rule ml_prep on cluster (jobid: 1, external: Submitted batch job 9706206, jobscript: /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/.snakemake/tmp.0ql88bj0/snakejob.ml_prep.1.sh). For error details see the cluster log and the log files of the involved rule(s).
Cleanup job metadata.
Cleanup failed jobs output files.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-18T111417.170561.snakemake.log
unlocking
removing lock
removing lock
removed all locks
