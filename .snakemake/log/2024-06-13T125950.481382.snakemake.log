Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job stats:
job        count
-------  -------
ml_prep        2
targets        1
total          3

Select jobs to execute...
Execute 2 jobs...

[Thu Jun 13 12:59:52 2024]
localrule ml_prep:
    input: Data/groundtruth.tokens.csv.gz, Code/MLprep.R, Data/groundtruth.csv
    output: Data/groundtruth.new_seq_data.preprocessed.RDS
    jobid: 1
    reason: Missing output files: Data/groundtruth.new_seq_data.preprocessed.RDS
    wildcards: datasets=groundtruth, ml_variables=new_seq_data
    resources: tmpdir=/tmp


[Thu Jun 13 12:59:52 2024]
localrule ml_prep:
    input: Data/gt_subset_30.tokens.csv.gz, Code/MLprep.R, Data/gt_subset_30.csv
    output: Data/gt_subset_30.new_seq_data.preprocessed.RDS
    jobid: 5
    reason: Updated input files: Code/MLprep.R
    wildcards: datasets=gt_subset_30, ml_variables=new_seq_data
    resources: tmpdir=/tmp

[Thu Jun 13 13:01:08 2024]
Error in rule ml_prep:
    jobid: 1
    input: Data/groundtruth.tokens.csv.gz, Code/MLprep.R, Data/groundtruth.csv
    output: Data/groundtruth.new_seq_data.preprocessed.RDS
    shell:
        
        Code/MLprep.R Data/groundtruth.csv Data/groundtruth.tokens.csv.gz new_seq_data 16 Data/groundtruth.new_seq_data.preprocessed.RDS
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Waiting at most 5 seconds for missing files.
MissingOutputException in rule ml_prep in file /nfs/turbo/schloss-lab/jocolova/Colovas_Data_Accessibility/Snakefile, line 51:
Job 5  completed successfully, but some output files are missing. Missing files after 5 seconds. This might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait:
Data/gt_subset_30.new_seq_data.preprocessed.RDS (missing locally, parent dir contents: 2150-7511_metadata.RDS, gt_subset_30.clean_html.csv.gz, gt_subset_30_data_clean_html.csv.gz, 2379-5077_metadata.RDS, groundtruth.tokens.csv.gz, groundtruth.csv.gz, gt_subset_30_data.csv.gz, gt_subset_30_new_seq_data_preprocessed.RDS, 1098-5336_metadata.RDS, 2165-0497_metadata.RDS, README.md, textstats, gt_subset_30_tokens.csv.gz, 1098-5522_metadata.RDS, groundtruth.clean_html.csv.gz, 2379-5042_metadata.RDS, add_to500.csv, 1098-5530_metadata.RDS, 1098-6596_metadata.RDS, gt_subset_30_data.json, gt_subset_30.tokens.csv.gz, groundtruth.csv, ac_papers_tocheck.csv, 0095-1137_metadata.RDS, 1935-7885_metadata.RDS, gt_subset_30.csv, seq_papers_bib_1300.csv, ml_results, gt_subset_30_html.csv.gz, 2576-098X_metadata.RDS, linkrot, groundtruth_clean_html.csv.gz, groundtruth_html.csv.gz, README.html, gt_subset_30_clean_html.csv.gz, 1098-5514_metadata.RDS, groundtruth.json)
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-06-13T125950.481382.snakemake.log
WorkflowError:
At least one job did not complete successfully.
